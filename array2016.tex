%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% numbers       To obtain numeric citation style instead of author/year.

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage[rgb,dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{graphics}
\usepackage{array} % tables
\usepackage{afterpage} % figures
\usepackage{float} % figures
\usepackage{paralist} % figures
\usepackage[shortcuts]{extdash} % figures
\usepackage{todonotes}
\usepackage{textcomp}
\usepackage{ marvosym }
\usepackage{dirtree}
% \usepackage{lmodern}
\usepackage{multirow,tabularx}
\usepackage{ctable}
\usepackage{relsize}
\usepackage{amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pifont}
\usepackage{amsthm}
\usepackage{siunitx}
 \sisetup{
    binary-units,
    detect-all,
    free-standing-units,
    space-before-unit,
    use-xspace,
    unit-optional-argument,
    parse-units = false,
  }
%\usepackage[scaled=0.9]{inconsolata}
\usepackage[scaled=0.85]{beramono}
\usepackage[final]{microtype}
\microtypesetup{stretch=9,shrink=15,step=3,letterspace=50}
% % Disable single lines at the start of a paragraph (Schusterjungen)
% \clubpenalty = 10000
% % Disable single lines at the end of a paragraph (Hurenkinder)
% \widowpenalty = 10000 
% \displaywidowpenalty = 10000 % formulas

\usepackage[pass,letterpaper]{geometry}

\usepackage{balance}
%\usepackage{subcaption}
\usepackage{subfig}
\usepackage{wrapfig}

\newcommand{\cL}{{\cal L}}

\lstset{
language=Ruby,
% backgroundcolor=\color[rgb]{0.95, 0.95, 0.95},
tabsize=2,
rulecolor=,
basicstyle=\ttfamily,
upquote=true,
% aboveskip={1.5\baselineskip},
columns=fullflexible,
% columns=fixed,
showstringspaces=false,
extendedchars=true,
breaklines=true,
prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
% frame=single,
showtabs=false,
showspaces=false,
showstringspaces=false,
% identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{1.0,0,0},
keywordstyle=[1]\color[rgb]{0,0,0.75},
keywordstyle=[2]\color[rgb]{0.5,0.0,0.0},
keywordstyle=[3]\color[rgb]{0.127,0.427,0.514},
keywordstyle=[4]\color[rgb]{0.4,0.4,0.4},
commentstyle=\color[rgb]{0,0,0},
stringstyle=\color[rgb]{0.639,0.082,0.082},
morekeywords={self, proceed},
%numbers=left,%
numbersep=5pt,%
numberstyle=\tiny\color{gray},%
emphstyle=\bfseries,%
breaklines=true,
breakatwhitespace=true,%
escapechar=`,
}
\lstset{escapeinside={<@}{@>}}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{ARRAY '16}{Month d--d, 20yy, Malaga, Spain}
\copyrightyear{2016}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

% Uncomment the publication rights you want to use.
%\publicationrights{transferred}
\publicationrights{licensed}     % this is the default
%\publicationrights{author-pays}
\toappear{}

\titlebanner{Submitted for review to ARRAY 2016}        % These are ignored unless
\preprintfooter{Ikra: Object-oriented GPGPU Programming in Ruby with CUDA}   % 'preprint' option specified.

\title{Ikra: Object-oriented GPGPU Programming \\ in Ruby with CUDA}
%\title{A Layer-based Approach to Hierarchical Dynamically-scoped Class Extensions}

\subtitle{Research Paper}

\newcommand\Mark[1]{\textsuperscript#1}  
\authorinfo{Matthias Springer\and Hidehiko Masuhara}
           {Department of Mathematical and Computing Sciences, Tokyo Institute of Technology, Japan}
           {matthias.springer@acm.org \and masuhara@acm.org}     
\maketitle

\setcitestyle{square}

\captionsetup{labelfont=bf}

\begin{abstract}
We present Ikra, a Ruby-to-CUDA just-in-time compiler. The high-level goal of Ikra is to allow researchers, who are not familiar with CUDA and GPU-specific architectural details, to take advantage of GPU-based high-performance machines.

Ikra analyzes parallel sections in the form of array operations (e.g., \texttt{map}, \texttt{select}, or \texttt{each}), performs type inference upon invocation, and generates a CUDA kernel. To reduce thread divergence, Ikra reorders the base array based on the type information, which is useful for programs that were designed in an object-oriented way. Objects are represented as columns, giving rise to memory coalescing. Although programmers are advised to write statically-typed Ruby code for performance reasons, Ikra can generate CUDA code for expressions that can be one of multiple types using class tags.
\end{abstract}

\category{D.3.3}{Programming Languages}{Language Constructs and Features}

% general terms are not compulsory anymore,
% you may leave them out
%\terms
%term1, term2

\keywords
Class extension, context-oriented programming, mixins

\section{Introduction}
With the availability and affordability of powerful GPUs, general purpose computing on graphics processing units (GPGPU) is becoming more and more popular in high-performance computing. Nowadays, many supercomputers rely on GPUs as main processing units, because they allow for massively parallel execution of algorithms or simulations with thousands of threads per GPU. However, GPU programming differs from traditional CPU programming, mostly because of architectural differences.

The goal of the Ikra project is to make GPU programming available to researchers who are not familiar with the details of GPUs their programming languages. Ikra is a library for Ruby that translates parallel sections to CUDA code and executes them in parallel on GPUs. We target the Ruby programming language because it provides powerful mechanisms for embedding DSLs in the language, which will be useful for later experiments.

\section{Example: Actor-based Traffic Simulation}
A simple actor-based traffic simulation will serve as a running example in this paper. The basic idea is to simulate the behavior of a number of actors (e.g., cars, buses, pedestrians, etc.), given a street network as a directed graph (Figure~\ref{fig:running_example}) in adjacency list representation. Every actor is located on one street. Every street has a \emph{length} attribute and every actor has a \emph{progress} attribute representing the distance from the beginning of the street. Once these two attributes have the same value, the actor reached an intersection and should be moved to a different street (or make a U-turn if there is no other neighboring street).

A car moves at a constant speed of \texttt{@max\_velocity}. A predestrian moves at a random speed between $-0.5 \times \texttt{@max\_velocity}$ and $\texttt{@max\_velocity}$, i.e., a pedestrian can make negative progress. This is how we model strolling pedestrains. Furthermore, the progress of actors might be affected by weather conditions depending on their type. For example, cars slow down if the weather conditions are bad, whereas pedestrians are not affected by weather conditions.

\begin{figure}[!htp]
    \centering
    \subfloat[Actual street network (map)]{{\includegraphics[width=\columnwidth]{running_example.pdf} }}%
    
    \subfloat[Street network as directed graph]{{\includegraphics[width=\columnwidth]{running_example_graph.pdf} }}%
    \caption{Street Network for Traffic Simulation}
    \label{fig:running_example}%
\end{figure}

\paragraph{Data Structure}
\begin{figure}[!htp]
    \centering
    \includegraphics[width=0.8\columnwidth]{class_diagram_running_ex.pdf}
    \caption{Class Diagram for Traffic Simulation}
    \label{fig:running_example_classes}
\end{figure}

The street network and the actors are designed in an object-oriented way. Figure~\ref{fig:running_example_classes} shows the class organization of the traffic simulation. \texttt{Car} and \texttt{Pedestrian} are subclasses of \texttt{Actor} and provide their own \texttt{move} methods which will be invoked for every tick of the simulation. 

\paragraph{Main Simulation Loop}
The following code snippet contains the main simulation functionality. The method \texttt{pmap} designates a parallel section. Its parameter \texttt{ticks} determines how often the entire \texttt{peach} statement should be executed and is equivalent to wrapping the \texttt{peach} statement in a loop that executes it \texttt{ticks} times\footnote{Ikra does not support nested loops properly, which is why we suggest using this shortcut. See Section~\ref{sec:nested_loops} for more details.}.

\begin{lstlisting}
actors = [...]
ticks = 1000
weather = Weather::Rainy

actors.peach(ticks) <@\textbf{do}@> |actor|
    actor.move(weather)
<@\textbf{end}@>
\end{lstlisting}


\section{Architecture}
Ikra is a library for Ruby. It adds functionality to arrays to execute \texttt{map}, \texttt{select} and \texttt{each} operations in parallel. Programmers can \emph{require} Ikra in Ruby files, upon which new parallel versions of array operations are available (e.g., \texttt{pmap}). These parallel array operations take a block as an argument and designate the only parts of a Ruby programs that are parallelized using Ikra. The default behavior is to spawn one thread per array element, which is why all these computations must be independent of each other. Every \emph{tick} of the simulated progresses the current time by a certain constant value and actors are required to update their progress and street attributes accordingly.

\subsection{Compilation Process}
Figure~\ref{fig:overview_arch} gives a high-level overview of Ikra's compilation process. Upon invocation of a parallel section, Ikra acquires the source code of the parallel block, generates an abstract syntax tree (AST), and infers the type of all expressions. As a result, the type of every local and instance variable is known. In the best case, the type of an expression is monomorphic and primitive, but Ikra also supports arbitrary Ruby classes as types, as well as polymorphic types (see Section~\ref{sec:polymorphic}). The type inferer traverses invoked methods in a may-point-to fashion\footnote{Methods of all possible receiver types are taken into account.}. Based on the type-annotated AST, Ikra generates CUDA kernel code and boilerplate code for kernel invocation, and compiles the CUDA code using the nVidia CUDA toolchain. The result is a shared library which is loaded via Ruby's foreign function interface. Before kernel invocation, the base array along with all reachable objects (via instance variables) is transferred to the GPU's global memory. After kernel invocation, all changed objects and the result of the parallel section (if applicable) are written back to Ruby.

\begin{figure}[!htp]
    \includegraphics[width=\columnwidth]{high_level_arch.pdf}
    \caption{Overview of Ikra's Architecture}
    \label{fig:overview_arch}
\end{figure}

\subsection{Integration in Ruby}
In contrast to some other projects, Ikra transforms Ruby code to CUDA code while the Ruby program is running (just-in-time compilation). Therefore, Ikra can determine the types of variables that are passed into parallel sections at runtime instead of doing a dataflow analysis of the entire program. This is not only faster but also more accurate in the light of reflection and metaprogramming, which is allowed outside of parallel sections but not inside them.

Two different kinds of variables can be used inside a parallel section: iterator variables and lexical variables. In the following code snippet, \texttt{el} is an iterator variable and \texttt{increment} is a lexical variable. The types of these variables are used as the foundation for type inference of the remaining parallel section.
\begin{lstlisting}
increment = 10
[1, 2, 3].pmap <@\textbf{do}@> |el|
    el + increment
<@\textbf{end}@>
\end{lstlisting}

Programmers can use not only primitive objects (\texttt{Fixnum}, \texttt{Float}, etc.) but also objects which are instances of Ruby classes inside parallel sections, allowing for object-oriented modelling of the problem (e.g., a traffic simulation). Consequently, a graph of \emph{reachable} (connected) objects must be transferred to the GPU. The \emph{object tracer} is responsible for determining which objects should be copied to the GPU's global memory (see Section~\ref{sec:impl_tracer}).

After kernel execution, changed local variables and instance variables are copied back to the Ruby side (see Section~\ref{sec:impl_copyback}).


\section{Implementation and Optimizations}
In this section, we give an overview of some interesting aspects of Ikra's implementation.

\subsection{Job Reordering}
Before kernel invocation, Ikra analyzes all elements in the base array and reorders them according to their type. This is useful to avoid \emph{thread divergence}, which can penalize performance when running programs on GPUs.

\paragraph{Thread Divergence}
In contrast to most CPU-based systems\footnote{There are CPU extensions for SIMD computations, e.g., SSE.}, GPU-based systems are SIMD (single instruction, multiple data) systems. A GPU consists of a number of streaming multiprocessors. Such a processor has a single control unit that fetches and decodes instructions, but multiple arithmetic logic units (ALUs). Therefore, every instruction is executed in parallel on multiple chunks of data. Every ALU corresponds to one thread, but all threads that are executing on the same stream multiprocessor must follow the same control flow. In case two threads take a different branch, their execution is serialized until the control flow merges again. Consequently, jobs should be threads/jobs should be mapped to streaming multiprocessors in such a way that the control flow is unlikely to divergenge among one such thread group (threads executing on one stream multiprocessor).

In CUDA, such a thread group is called \emph{warp} and typically has a size of 32. There is no explicit interface to allocate threads to warps, but CUDA programmers try to write their programs in such a way that each consecutive group of 32 threads follows the same control flow.

\paragraph{Thread Allocation}
Ikra tries to avoid thread divergence by allocating jobs to warps automatically based on type information. Before kernel invocation, Ikra generates a \emph{job reordering array}, such that the base array is sorted according the elements' types (Figure~\ref{fig:ex_job_reorder}). Ikra does not actually change the order elements in the base array to ensure that other parts of the program outside of the parallel section are not affected.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\columnwidth]{reorder_example.pdf}
    \caption{Example: Job Reordering. The first row is the original job order, the second row is the job reordering array, and the third row shows the resulting job order (warp size 4).}
    \label{fig:ex_job_reorder}
\end{figure}

During job reordering the number of threads can increase as shown in Figure~\ref{fig:ex_job_reorder}. Jobs are reordered in such a way that no two elements of different type are allocated in the same warp. If the number of jobs of a particular type is not a multiple of the warp size, the last warp will not be filled up entirely, but some threads will not have a job, i.e., they are not \emph{no operation} threads. This might seem like a waste of computing power, but we expect the number of different types to be small (3 in this example).

The job reordering array can be computed in linear time by scanning all elements of the base array twice. The following pseudo code is similar to counting sort and bucket sort~\cite{Corwin:2004:SLT:1040231.1040257}. It generates one array of indices per type (class) and concatenates these arrays, making sure that every new array starts at a multiple of the warp size $W$.

\begin{algorithm}
\caption{Job Reordering}
\label{CHalgorithm}
\begin{algorithmic}[1]
\Procedure{ReorderingArray}{base, W}
\State $\mathit{types} \gets$ Hash.new
\ForAll {$(\mathit{el}, \mathit{idx}) \in \mathit{base}$}
    \State $\mathit{types}[\mathit{el}.\mbox{class}].\mbox{add}(\mathit{idx})$
\EndFor
\State $\mathit{result} \gets$ Array.new$(\sum_{\mathit{arr} \in \mathit{types}.\mathit{values}} \lceil |\mathit{arr}| / W \rceil * W)$
\State $\mathit{next} \gets 0$
\ForAll {$\mathit{arr} \in \mathit{types}.\mbox{values}$}
    \ForAll {$\mathit{idx} \in \mathit{arr}$}
        \State $\mathit{result}[\mathit{next}] = \mathit{idx}$
        \State $\mathit{next} \gets \mathit{next} + 1$
    \EndFor
    \State $\mathit{next} \gets \lceil \mathit{next} / W \rceil * W$
\EndFor
\State \Return $\mathit{result}$
\EndProcedure
\end{algorithmic}
\end{algorithm}


\subsection{Columnar Object Layout}
Objects are typically represented row-wise, i.e., every object is a contiguous chunk of data in the memory. Based on observations in previous work on GPU-powered database query execution~\cite{Bakkum:2010:ASD:1735688.1735706} where a column-wise data organization proved to be superior compared to a traditional row-based data layout, Ikra stores objects in a columnar layout~\cite{Mattis:2015:COI:2814228.2814230}.

\paragraph{Memory Coalescing}
Global memory is one of the main bottlenecks of GPUs. One approach is to aim for memory access patterns where memory that is accessed in parallel by a number of threads is spatially local. Such memory accesses can be coalesced, i.e., the GPU can process such accesses in a single request, alleviating the global memory bottleneck.

Since a GPU is a SIMD system, all threads within a warp have to execute the same instruction at a time. Consequently, if one thread accesses an instance variable, then all other threads within the same warp access the same instance variable (or block because of thread divergence), probably in a different object. In this situation, a columnar object layout is superior to a row-based object layout, because parallel accesses to the same instance variable are more likely to be spatially local (Figure~\ref{fig:ex_obj_layout}).

\begin{figure}[!htp]
    \centering
    \subfloat[Row-based Layout (uncoalesced)]{{\includegraphics[width=0.75\columnwidth]{column_access_1.pdf} }}%
    
    \subfloat[Column-based Layout (maybe coalesced)]{{\includegraphics[width=0.75\columnwidth]{column_access_2.pdf} }}%
    \caption{Example: Row-based and Column-based Object Layout. Boxes represent instance variables. Arrows indicate parallel access.}
    \label{fig:ex_obj_layout}%
\end{figure}

\paragraph{Generating Columns}
In the following, we present a first approach for representing object as columns. For the moment, we assume that all source code is statically typed and the types of all expressions and variables could be inferred successfully. This approach will be extended in the light of polymorphic expressions in the next section.

After running the object tracer, we know which objects should be transferred to the GPU. These objects are processed as follows.
\begin{enumerate}
    \item Group objects by class $c$, resulting in arrays $O_c$.
    \item Assign an ID to every object for all $O_c$, starting from $0$ in every $O_c$, IDs being consecutive. This results in a hash map $H_c$ mapping objects to class-specific IDs.
    \item For every instance variable $v$ of every class $c$, create an array (column) $A_{c,v}$ of size $m + 1$, where $m$ is the maximum ID in $O_c$. The base type of the array is the type of the instance variable if it is primitive, or \texttt{int} otherwise (referencing other non-primitive object via its ID).
    \item Traverse the object graph. For every visited object $o$ , determine its class $c$ and ID $H_c[o]$. Store every instance variable $v$ in the corresponding column slot $A_{c, v}[H_c[o]]$. If the instance variable is non-primitive, look up its ID and store it.
\end{enumerate}
Note that after this transformation, the type of the base array that is passed to the kernel, is of type \texttt{int} and contains object IDs if it contains non-primitive objects.

\paragraph{Source Code Transformation}
Since objects are now represented as fields of arrays, Ikra must generate different source code for read from or writing to instance variables. We continue to assume that the type of all expressions and varibles is known unambiguously. Moreover, we do not consider generating new objects at this time (see Section~\ref{sec:gen_new_obj}).

In the following, we consider reading/writing instance variables of an object and calling methods on an object, where the object is identified by its type $c$ and its ID $i$. Whenever objects are passed around, Ikra actually generates source code that passes its ID around. Passing type information is not necessary, because we assume that we know the type of every expression and variable\footnote{We consider subclasses to be an entirely different type in this section.}.

Reading an instance variable $v$ of object $o$ with type $c$ and ID $i$ translates to reading the column $A_{c,v}[i]$. Writing an instance variable translates to writing into the same column at the same position.

Every instance method is translated to a device function, where the type $c$ is mangled into its name and the first parameter has type \texttt{int} and represents the ID of \texttt{self} object. Whenever Ikra encounters a method call during code translation, it determines the receiver's type and generates a call to the appropriate device function.


%One approach to alleviate that problem is to aim for a high occupancy to hide memory latency, i.e., running a high number of threads, such that the GPU can switch execution to another warp while the current thread is blocking. Another optimization is to aim for coalesced mem

\subsection{Dynamically-typed Expressions}
\label{sec:polymorphic}
In contrast to CUDA, Ruby is a dynamically-typed programming language. One of the goals of the Ikra project is to allow programmers to write Ruby code in a \emph{natural} way, i.e., programmers should be able to write the same source code that they would write in a standard Ruby environment. For this reason, Ikra should also support Ruby expression whose types cannot be inferred unambiguously at translation time.

Ikra embeds dynamic types into CUDA's static type system by generating explicit type dispatch statements at method call sites based on type tags~\cite{Abadi:1989:DTS:75277.75296} for receivers whose types cannot be inferred unambiguously. From a perspective of object-oriented design, this looks as if every object has a \emph{type} instance variable.

\paragraph{Class Tags}
To support dynamically-typed expressions, we extend the idea of class-specific object IDs as follows. The following mechansim is applied only if the type of an expression or variable cannot be uniquely inferred. Otherwise, the previously described (non-extended) mechanism is applied. 

Whenever an object ID was previously used, we now use a tuple of object ID and \emph{class ID}. A class ID is a unique \texttt{int} identifier for a certain class. Class tags are used for object references and for method calls. A Ruby variable is now represented by two CUDA \texttt{int} variables: one for the class tag and one for the object ID. Similarly, when passing an object as an argument, the same two arguments are passed in the generated CUDA code.

Before dispatching to a method, the generated CUDA cude determines the type of the receiver in a switch statement to select the corresponding instance method. In the following example, two arrays (actor tags and actor IDs) are passed to the kernel function. The device function representing the block invokes the correct instance method.

\lstset{language=C++}
\begin{lstlisting}
<@\textbf{\_\_global\_\_ void}@> kernel(<@\textbf{int}@> *jobs, <@\textbf{int}@> *actor_tag, <@\textbf{int}@> *actor_id)
{
  <@\textbf{int}@> tid = blockIdx.x * blockDim.x + threadIdx.x;
  block(actor_tag[jobs[id]], actor_id[jobs[id]]);
}

<@\textbf{\_\_device\_\_ void}@> block(<@\textbf{int}@> actor_tag, <@\textbf{int}@> actor_id)
{
  <@\textbf{for}@> (<@\textbf{int}@> i = 0; i <= ticks; i++)
  {
    <@\textbf{switch}@> (actor_tag)
    {
      <@\textbf{case}@> TAG_Car:
        method_Car_move(actor_id, weather);
        <@\textbf{break}@>;
      <@\textbf{case}@> TAG_Pedestrian:
        method_Pedestrian_move(actor_id, weather);
        <@\textbf{break}@>;
      <@\textbf{default}@>:
        <@\textit{/* same mechansim to dispatch to method\_missing */}@>
    }
  }
}
\end{lstlisting}

\paragraph{Object Layout}
In the light of class tags, we extend the columnar object layout as follows. If Ikra cannot infer the type of an instance variable unambiguously, two columns are created for that instance variable: one for the class tag and one for the object ID.

\paragraph{Polymorphism}
In terms of type inference, subclasses are treated as entirely different types instead of subtypes. For example, if type inference determines that the type of a variable can be \texttt{Car} or \texttt{Pedestrian}, the type of that variable is the set $\{\texttt{Car}, \texttt{Pedestrian}\}$ instead of \texttt{Actor}. In this case, the type dispatch statements for a method call contains can handle only \texttt{Car} and \texttt{Pedestrian}, but not, for example, \texttt{Bus}, which is also a subclass of \texttt{Actor}. If a method is only implemented in a superclass (e.g., \texttt{Actor}), but not in the receiver's class itself (e.g., \texttt{Car}), the type dispatch statements can dispatch to that method directly, since that case can be detected at translation time. In addition to the object ID of the \texttt{self} (receiver) object, its class ID is also passed as an argument during method calls.

Instance variables are stored together with the first class in the superclass hierarchy, in which they were used for the first time. For example, \texttt{@street} is stored as a column of class \texttt{Actor}. Subclasses and superclass share the same IDs. If an object is an instance of a different subclass, the corresponding column values are \emph{null} values~\cite{Mattis:2015:COI:2814228.2814230}. For example, if object 15 is a \texttt{Pedestrian}, then $A_{\texttt{Car}, \texttt{@max\_velocity}}[15]$ is null.

\subsection{Read/write Analysis for Instance Variables}

\subsection{Copying back Variables}
\label{sec:impl_copyback}

\subsection{Object Tracer}
\label{sec:impl_tracer}


\section{Optimizations}
% Only write back objects if they are accessed; how can we hook into object access? Proxies?


\section{Benchmarks}

\section{Related Work}

\section{Future Work}

\subsection{Nested Loops}
\label{sec:nested_loops}
Ikra does not yet support nested loops properly. Putting a \texttt{ticks} loop inside the \texttt{peach} block works but contradicts intuition. In a sequential program, most programmers would formulate the simulation code as a series of simulation ticks, where every simulation tick iterates over all actors, as opposed to iterating of over all actors, where every actor is moved for a series of simulation ticks.

\begin{lstlisting}
actors.peach do |actor|
    for i in 1..ticks
        actor.move(weather)
        synchronize
    end
end
\end{lstlisting}

The following code snippet is more intuitive, but would allocate one thread per tick instead of one thread per actor. However, the mechanism described in this paper takes advantage of allocating threads based on the actors' types.
\begin{lstlisting}
(1..ticks).peach do
    actors.each do |actor|
        actor.move(weather)
    end
end
\end{lstlisting}

\subsection{Generating New Objects}
\label{sec:gen_new_obj}

\section{Conclusion}

% We recommend abbrvnat bibliography style.

\bibliographystyle{plain}
\bibliography{array2016}


\end{document}
